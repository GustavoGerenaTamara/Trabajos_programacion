{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOegzE1cwwN+uFULOV8Y2a6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavoGerenaTamara/Trabajos_programacion/blob/main/Clasificadores_Gustavo_Gerena.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNIVERSIDAD DISTRITAL FRANCISCO JOSÉ DE CALDAS\n",
        "## TÓPICOS AVANZADOS EN AUTOMÁTICA 2022-3\n",
        "### MAESTRÍA EN INGENIERÍA\n",
        "### Gustavo Gerena\n",
        "\n",
        "---\n",
        "### MÉTODOS DE CLASIFICACIÓN\n",
        "\n",
        "Para realizar la evaluación de los métodos de clasificación vistos, se realiza el siguiente paso a paso:\n",
        "\n",
        "1. Seleccionar un conjunto de datos, en este caso es una base de datos que se extrajo de: https://archive.ics.uci.edu/ml/datasets/arrhythmia;\n",
        "esta contiene información sobre las condiciones que podrían servir para predecir si se puede presentar o no una arritmia.\n",
        " \n",
        "Selección de columnas relevantes\n",
        "1 Age: Age in years , linear\n",
        "3 Height: Height in centimeters , linear\n",
        "4 Weight: Weight in kilograms , linear\n",
        "5 QRS duration: Average of QRS duration in msec., linear\n",
        "10 QRS \n",
        "Selección de columna de salida\n",
        "10 QRS\n",
        "En los electrocardiogramas los valores normales hallados son la frecuencia cardiaca con un valor mínimo de 60 y máximo de 80, la duración de QRS de 68 a 100, el intervalo QT de 314 a 430, intervalo PR, 124 a 189, onda P 36 a 120, intervalo RR 615 a 1000 y su eje de QRS de -28 a 94.\n",
        "\n",
        "\n",
        "Se dividen los datos para entrenamiento y pruebas, para ello se usarán 70%/30%,  para evitar el overfittitng \n",
        "Fuente: https://empresas.blogthinkbig.com/datos-entrenamiento-vs-datos-de-test/#:~:text=Normalmente%20el%20conjunto%20de%20datos,el%20sobreajuste%20u%20%E2%80%9Coverfitting%E2%80%9D.\n",
        "Balancear BD \n",
        "\n",
        "Cargamos el dataset disponible en https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data ; esta base de datos contiene 279 atributos, 206 de los cuales son de valor lineal y el resto son nominales.\n",
        "\n",
        "El objetivo es distinguir entre la presencia y ausencia de arritmia cardíaca y clasificarla en uno de los 16 grupos. La clase 01 se refiere a ECG 'normal'. Las clases 02 a 15 se refieren a diferentes clases de arritmia y la clase 16 se refiere al resto de las no clasificadas"
      ],
      "metadata": {
        "id": "ED24vZKvXLNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos los datos de una carpeta local\n",
        "f_in = open(\"arrhythmia.data\",'r')\n",
        "arrhythmia = f_in.readlines()\n",
        "f_in.close()\n"
      ],
      "metadata": {
        "id": "4Pw8oxJVClG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "alturas_cm=[]\n",
        "pesos_kg=[]\n",
        "Frecuencia_cardiaca=[] #Número de latidos cardíacos por minuto\n",
        "Num_de_deflex=[]\n",
        "T = [] #Duración media de la onda T en mseg\n",
        "P = [] #Duración media de la onda P en mseg\n",
        "Onda_Q=[] #Ancho promedio, en mseg onda Q\n",
        "Onda_R=[] #Ancho promedio, en mseg onda R\n",
        "Onda_S=[] #Ancho promedio, en mseg onda S\n",
        "P_R = [] #duración promedio entre el inicio de las ondas P y R en mseg\n",
        "Q_T = [] #duración promedio entre el inicio de Q y el final de las ondas T en mseg\n",
        "grupos=[]\n",
        "for renglon in arrhythmia:\n",
        "  datos_ren_str = renglon.split(',')\n",
        "  try:\n",
        "      altura_cm = int(datos_ren_str[2])\n",
        "      if altura_cm > 200:\n",
        "        continue\n",
        "      peso_kg = int(datos_ren_str[3])\n",
        "      p_r = int(datos_ren_str[5])\n",
        "      q_t = int(datos_ren_str[6])\n",
        "      t = int(datos_ren_str[7])\n",
        "      p = int(datos_ren_str[8])\n",
        "      frecuencia_cardiaca = int(datos_ren_str[14])\n",
        "      Onda_q = int(datos_ren_str[15])\n",
        "      Onda_r = int(datos_ren_str[16])\n",
        "      Onda_s = int(datos_ren_str[17])\n",
        "      num_de_deflex = int(datos_ren_str[20]) \n",
        "      grupo = int(datos_ren_str[-1])\n",
        "  except:\n",
        "     continue\n",
        "  alturas_cm.append(altura_cm)\n",
        "  pesos_kg.append(peso_kg)\n",
        "  Frecuencia_cardiaca.append(frecuencia_cardiaca)\n",
        "  Num_de_deflex.append(num_de_deflex)\n",
        "  T.append(t)\n",
        "  P.append(p)\n",
        "  Onda_Q.append(Onda_q)\n",
        "  Onda_R.append(Onda_r)\n",
        "  Onda_S.append(Onda_s)\n",
        "  P_R.append(p_r)\n",
        "  Q_T.append(q_t)\n",
        "  grupos.append(grupo)\n",
        "\n",
        "minima,maxima=min(pesos_kg),max(pesos_kg)\n",
        "peso_car=[int((i-minima)/10) for i in pesos_kg  ]\n",
        "\n",
        "minima,maxima=min(alturas_cm),max(alturas_cm)\n",
        "altura_car=[int((i-minima)/10) for i in alturas_cm  ]\n",
        "\n",
        "minima,maxima=min(Frecuencia_cardiaca),max(Frecuencia_cardiaca)\n",
        "Frecuencia_cardiaca_car=[int((i-minima)/10) for i in Frecuencia_cardiaca  ]\n",
        "\n",
        "minima,maxima=min(Num_de_deflex),max(Num_de_deflex)\n",
        "Num_de_deflex_car=[int((i-minima)/10) for i in Num_de_deflex  ]\n",
        "\n",
        "minima,maxima=min(T),max(T)\n",
        "T_car=[int((i-minima)/10) for i in T  ]\n",
        "\n",
        "minima,maxima=min(P),max(P)\n",
        "P_car=[int((i-minima)/10) for i in P  ]\n",
        "\n",
        "minima,maxima=min(Onda_Q),max(Onda_Q)\n",
        "Onda_Q_car=[int((i-minima)/10) for i in Onda_Q  ]\n",
        "\n",
        "minima,maxima=min(Onda_R),max(Onda_R)\n",
        "Onda_R_car=[int((i-minima)/10) for i in Onda_R  ]\n",
        "\n",
        "minima,maxima=min(Onda_S),max(Onda_S)\n",
        "Onda_S_car=[int((i-minima)/10) for i in Onda_S  ]\n",
        "\n",
        "minima,maxima=min(P_R),max(P_R)\n",
        "P_R_car=[int((i-minima)/10) for i in P_R ]\n",
        "\n",
        "minima,maxima=min(Q_T),max(Q_T)\n",
        "Q_T_car=[int((i-minima)/10) for i in Q_T ]\n",
        "\n",
        "minima,maxima=min(grupos),max(grupos)\n",
        "grupos_car=[i-1 for i in grupos ]\n",
        "\n",
        "\n",
        "\n",
        "#data = pd.DataFrame(list(zip(altura,peso,Frecuencia_cardiaca,Num_de_deflex,T_car,P,Onda_Q,Onda_R,Onda_S,P_R,Q_T,grupos)),\n",
        " #                           columns =['alturas_cm', 'pesos_kg','Frecuencia_cardiaca','Num_de_deflex','T','P','Onda_Q','Onda_R','Onda_S','P_R','Q_T','Salida']) # No escalados\n",
        "data = pd.DataFrame(list(zip(altura_car,peso_car,Frecuencia_cardiaca_car,Num_de_deflex_car,T_car,P_car,Onda_Q_car,Onda_R_car,Onda_S_car,P_R_car,Q_T_car,grupos_car)),\n",
        "                            columns =['alturas_cm', 'pesos_kg','Frecuencia_cardiaca','Num_de_deflex','T','P','Onda_Q','Onda_R','Onda_S','P_R','Q_T','Salida'])\n",
        "data.head()"
      ],
      "metadata": {
        "id": "G-zeqTVUWnbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-procesamiento de datos\n",
        "Ya que utilizaremos un metodo de clasificación basada en regresión logistica, es necesario ajustar la salida a 0 o 1, donde:\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Salida</th>\n",
        "    <th>Salida ajustada</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Paciente sin arritmia (0)</td>   \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>2-16</td>\n",
        "    <td>Paciente con arritmia (1)</td>   \n",
        "  </tr>\n",
        "   \n",
        "</table>\n",
        "Lo anterior indica que si la salida es 0 el diagnostico es negativo, de lo contrario el diagnostico es positivo."
      ],
      "metadata": {
        "id": "Q7Ja8U-alDua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos el preprocesamiento de la salida\n",
        "Pre_out = data['Salida'].copy() # Creamos una copia de la columna de salida.\n",
        "for index, value in enumerate(grupos):\n",
        "    if value == 1:\n",
        "      Pre_out[index] = 0\n",
        "    else:\n",
        "      Pre_out[index] = 1\n",
        "Pre_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w94wdS2jmvC4",
        "outputId": "501a3eca-7014-4932-c852-0cd57703607c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      0\n",
              "4      1\n",
              "      ..\n",
              "444    0\n",
              "445    1\n",
              "446    1\n",
              "447    0\n",
              "448    0\n",
              "Name: Salida, Length: 449, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De esta forma aseguramos que la salida (y) sea un 1 o 0, de tal forma que podamos usar el metodo de regresión logistica como clasificador\n",
        "Selección datos de entrada y salida del dataset creado previament\n"
      ],
      "metadata": {
        "id": "2aZproegXXmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:,:11] # Seleccionamos las primeras 11 columnas del DataFrame correspondiente a las entradas\n",
        "y = Pre_out # Seleccionamos la Salida previamente modificada\n",
        "m,n = X.shape\n",
        "m,n"
      ],
      "metadata": {
        "id": "diKsaZZiXeWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "np.random.seed(7)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "plt.rcParams['image.cmap'] = \"bwr\"\n",
        "plt.rcParams['savefig.bbox'] = \"tight\"\n",
        "style.use('ggplot') or plt.style.use('ggplot')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# División de los datos en train y test\n",
        "# ==============================================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                       X,\n",
        "                                       y,\n",
        "                                        train_size   = 0.5,\n",
        "                                        random_state = 1234,\n",
        "                                        shuffle      = True)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "2-2tqzSKXkcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nicialmente realizaremos el ejercicio de clasificación con los datos de entrada sin ningun tipo de modificación.\n",
        "#Vecino mas cercano"
      ],
      "metadata": {
        "id": "sjtOCXQyXrF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.linalg.decomp_svd import zeros\n",
        "k_min, err_min = np.inf,np.inf\n",
        "i = 200\n",
        "ks, errores = np.zeros(i-1),np.zeros(i-1) # Declaramos los arreglos en donde se van a guardar los valores de k y el error\n",
        "for k in range(1,i,1):\n",
        "  model = KNeighborsRegressor(n_neighbors=k)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  error = mean_squared_error(y_test, y_pred)\n",
        "  ks[k-1] = k # Guardamos los valores de en un arreglo\n",
        "  errores[k-1] = error # Guardamos los valores de error de cada k en un arreglo\n",
        "  # Evaluamos el error minimo y guardamos el valor de k de dicho valor\n",
        "  if error<err_min:\n",
        "    err_min = error\n",
        "    kf = k\n",
        "    rmse_vecinosn = mean_squared_error(y_test, y_pred)\n",
        "print('El minimo error encontrado es',rmse_vecinosn,', cuyo valor de k es',kf)"
      ],
      "metadata": {
        "id": "xZAm9NO1X1B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bayes"
      ],
      "metadata": {
        "id": "F1Vt-3RxX5Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import CategoricalNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                       X,\n",
        "                                       y,\n",
        "                                        train_size   = 0.5,\n",
        "                                        random_state = 1234,\n",
        "                                        shuffle      = True)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "\n",
        "clf = CategoricalNB()\n",
        "clf.fit(X_train, y_train)\n",
        "rmse_Bayen = mean_squared_error(y_test, y_pred)\n",
        "presBn = accuracy_score(y_train, clf.predict(X_train))\n",
        "print('El error en la predicción corresponde a:',rmse_Bayen,',con una precisión de:',presBn)\n"
      ],
      "metadata": {
        "id": "vey6MV5XX_Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regresión Logistica"
      ],
      "metadata": {
        "id": "1vBjvO7GYDid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                       X,\n",
        "                                       y,\n",
        "                                        train_size   = 0.5,\n",
        "                                        random_state = 1234,\n",
        "                                        shuffle      = True)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "modelo = LogisticRegression()\n",
        "modelo.fit(X = X_train, y = y_train)\n",
        "presRLn = accuracy_score(y_train, modelo.predict(X_train))\n",
        "rmse_RLn = mean_squared_error(y_test, y_pred)\n",
        "print('El error en la predicción corresponde a:',rmse_RLn,',con una precisión de:',presRLn)\n"
      ],
      "metadata": {
        "id": "wC-cDJJzYH_t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}